{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On cuda:0\n"
     ]
    }
   ],
   "source": [
    "from augmented_modules import ResnetBlock, CondInstanceNorm, TwoInputSequential, CINResnetBlock, InstanceNorm2d\n",
    "from augmented_utils import *\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'On {device}')\n",
    "Tensor  = torch.cuda.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aca2178f247d4b3982d40e7325a73e97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=28550.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19296a3a89a94c669a342a258ce6b081",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12944.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#for quicker debugging purposes\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, num_samples):\n",
    "        # Generate synthetic data (you can replace this with your actual data)\n",
    "        self.data1 = torch.randn(num_samples, 3, 224, 224)\n",
    "        self.data2 = torch.randn(num_samples, 3, 224, 224)\n",
    "        self.labels1 = torch.arange(num_samples)  # Dummy labels (you can modify this)\n",
    "        self.labels2 = torch.arange(num_samples)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data1)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = {\n",
    "              'D img': self.data1[idx],\n",
    "              'D pm' : self.labels1[idx],\n",
    "              'L img': self.data2[idx],\n",
    "              'L pm' : self.labels2[idx]\n",
    "        }\n",
    "        return sample\n",
    "\n",
    "custom_dataset = CyDataset()\n",
    "# custom_dataset = CustomDataset(num_samples = 300 ) #\n",
    "# Create a DataLoader\n",
    "batch_size = 2\n",
    "train, val = train_test_split(custom_dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataloader = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import subprocess\n",
    "\n",
    "# def get_gpu_info():\n",
    "#     try:\n",
    "#         output = subprocess.check_output(['nvidia-smi', '--query-gpu=utilization.gpu,memory.total,memory.used,memory.free', '--format=csv,noheader,nounits'])\n",
    "#         output = output.decode('utf-8').strip().split('\\n')\n",
    "#         gpu_info = []\n",
    "#         for line in output:\n",
    "#             gpu_util, memory_total, memory_used, memory_free = map(int, line.split(','))\n",
    "#             gpu_info.append({\n",
    "#                 'gpu_utilization': gpu_util,\n",
    "#                 'memory_total': memory_total,\n",
    "#                 'memory_used': memory_used,\n",
    "#                 'memory_free': memory_free\n",
    "#             })\n",
    "#         return gpu_info\n",
    "#     except subprocess.CalledProcessError:\n",
    "#         return None\n",
    "\n",
    "# # Example usage:\n",
    "# gpu_info = get_gpu_info()\n",
    "# if gpu_info is not None:\n",
    "#     for i, gpu in enumerate(gpu_info):\n",
    "#         print(f\"GPU {i}:\")\n",
    "#         print(f\"  Utilization: {gpu['gpu_utilization']} %\")\n",
    "#         print(f\"  Memory Total: {gpu['memory_total']} MB\")\n",
    "#         print(f\"  Memory Used: {gpu['memory_used']} MB\")\n",
    "#         print(f\"  Memory Free: {gpu['memory_free']} MB\")\n",
    "# else:\n",
    "#     print(\"Error occurred while fetching GPU info.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# norm_layer_ = functools.partial(nn.InstanceNorm2d, affine=False)\n",
    "# mod = Latent_Encoder(nlatent=3, input_nc=3, nef=32, norm_layer=norm_layer_)\n",
    "# ex = torch.rand((5,3,224,224))\n",
    "\n",
    "# g = mod(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_prob_gaussian(z, mu, log_var):\n",
    "    res = - 0.5 * log_var - ((z - mu)**2.0 / (2.0 * torch.exp(log_var)))\n",
    "    res = res - 0.5 * math.log(2*math.pi)\n",
    "    return res\n",
    "\n",
    "def kld_std_guss(mu, log_var):\n",
    "    \"\"\"\n",
    "    from Appendix B from VAE paper:\n",
    "    Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "    https://arxiv.org/abs/1312.6114\n",
    "    KL = -0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    \"\"\"\n",
    "    kld = -0.5 * torch.sum(log_var + 1. - mu**2 - torch.exp(log_var), dim=1)\n",
    "    return kld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pixel_Level_Augmented_CycleGAN():\n",
    "    def __init__(self):\n",
    "        super(Pixel_Level_Augmented_CycleGAN,self).__init__()\n",
    "        \n",
    "        norm_layer_C = CondInstanceNorm\n",
    "        norm_layer_ = functools.partial(nn.InstanceNorm2d, affine=False)\n",
    "        \n",
    "        self.G_ST = CINResnetGenerator(nlatent=16, input_nc=3, output_nc=3, ngf=64, norm_layer=norm_layer_C,\n",
    "                 use_dropout=False, n_blocks=3, gpu_ids=[], padding_type='reflect')\n",
    "        \n",
    "        self.G_TS = CINResnetGenerator(nlatent=16, input_nc=3, output_nc=3, ngf=64, norm_layer=norm_layer_C,\n",
    "                 use_dropout=False, n_blocks=3, gpu_ids=[], padding_type='reflect')\n",
    "\n",
    "        self.D_T = NLayerDiscriminator(input_nc=3, ndf=64, n_layers=4, norm_layer=norm_layer_)\n",
    "        self.D_S = NLayerDiscriminator(input_nc=3, ndf=64, n_layers=4, norm_layer=norm_layer_)\n",
    "\n",
    "        self.D_Zs = Discriminator_Latent(nlatent=16, ndf=64)\n",
    "        self.D_Zt = Discriminator_Latent(nlatent=16, ndf=64)\n",
    "        \n",
    "        self.E_S = Latent_Encoder(nlatent=16, input_nc=6, nef=32, norm_layer=norm_layer_)\n",
    "        self.E_T = Latent_Encoder(nlatent=16, input_nc=6, nef=32, norm_layer=norm_layer_)\n",
    "\n",
    "        self.G_ST.to(device)\n",
    "        self.G_TS.to(device)\n",
    "        self.E_S.to(device)\n",
    "        self.E_T.to(device)\n",
    "        self.D_S.to(device)\n",
    "        self.D_T.to(device)\n",
    "        self.D_Zs.to(device)\n",
    "        self.D_Zt.to(device)\n",
    "\n",
    "        self.ganloss = GANLoss().to(device)       \n",
    "        self.cycleloss = torch.nn.L1Loss().to(device)               #difference between reconstructed img and original\n",
    "        self.identityloss = torch.nn.L1Loss().to(device)\n",
    "        \n",
    "        self.optimizer_GS = torch.optim.Adam(itertools.chain(self.G_ST.parameters(), self.E_T.parameters()), \n",
    "                                            lr=2e-4, betas = (0.5,0.999))\n",
    "        self.optimizer_GT = torch.optim.Adam(itertools.chain(self.G_TS.parameters(), self.E_S.parameters()),\n",
    "                                            lr=2e-4, betas = (0.5, 0.99))\n",
    "        \n",
    "  \n",
    "        self.optimizer_DS = torch.optim.Adam(itertools.chain(self.D_S.parameters(),self.D_Zs.parameters())\n",
    "                                             , lr = 2e-4/5., betas = (0.5,0.9))\n",
    "    \n",
    "        self.optimizer_DT = torch.optim.Adam(itertools.chain(self.D_T.parameters(),self.D_Zt.parameters())\n",
    "                                             , lr = 2e-4/5., betas = (0.5,0.9))\n",
    "\n",
    "        self.G_ST.apply(weights_init_normal)\n",
    "        self.G_TS.apply(weights_init_normal)\n",
    "        self.D_S.apply(weights_init_normal)\n",
    "        self.D_T.apply(weights_init_normal)\n",
    "\n",
    "        print('initialized')\n",
    "    def sample_images(self, dataloader, epochs, iters, save = False):\n",
    "        \n",
    "        batch = next(iter(dataloader))\n",
    "        \n",
    "        self.data_input(batch)\n",
    "        self.G_ST.eval()\n",
    "        self.G_TS.eval()\n",
    "        \n",
    "        self.forward_pass()\n",
    "\n",
    "        real_S = make_grid(self.real_S, nrow=5, normalize=True, scale_each=True, padding=1)\n",
    "        fake_T = make_grid(self.t_tilde, nrow=5, normalize=True, scale_each=True, padding=1)\n",
    "        reconS = make_grid(self.s_prime, nrow=5, normalize=True, scale_each=True, padding=1)\n",
    "        real_T = make_grid(self.real_T, nrow=5, normalize=True, scale_each=True, padding=1)\n",
    "        fake_S = make_grid(self.s_tilde, nrow=5, normalize=True, scale_each=True, padding=1)\n",
    "        reconT = make_grid(self.t_prime, nrow=5, normalize=True, scale_each=True, padding=1)\n",
    "        # Arange images along y-axis    \n",
    "        image_grid = torch.cat((real_S, fake_T, reconS, real_T, fake_S, reconT), 2)\n",
    "        plt.imshow(image_grid.cpu().permute(1,2,0))\n",
    "        plt.title('Real Source | Fake Target | Recon Source || Real Target | Fake Source | Recon Target')\n",
    "        plt.axis('off')\n",
    "        plt.gcf().set_size_inches(10, 6)\n",
    "        if save:\n",
    "            plt.savefig(os.path.join('Figure_PDFs', f'epoch_{str(e+1)}_iter{str(i+1)}.png'), bbox_inches='tight', pad_inches=0, facecolor='white')\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        \n",
    "    def data_input(self, batch):\n",
    "        self.real_S = batch['D img'].type(Tensor)\n",
    "        self.real_T = batch['B img'].type(Tensor)\n",
    "        self.real_lbl = batch['D pm'].type(Tensor).float()\n",
    "        \n",
    "        self.prior_S = self.real_S.data.new(self.real_S.size(0), 16, 1, 1).normal_(0, 1)\n",
    "        self.prior_T = self.real_T.data.new(self.real_T.size(0), 16, 1, 1).normal_(0, 1)\n",
    "                  \n",
    "    def forward_pass(self):\n",
    "        #S--->T forward pass\n",
    "        self.t_tilde = self.G_ST(self.real_S, self.prior_T) #shape checks out [BS, CH, H, W] ~ [5, 3, 224, 224] \n",
    "        self.s_mu, self.s_logvar = self.E_S(torch.cat((self.t_tilde, self.real_S), 1))\n",
    "        self.zeta_tilde_s = reparameterize(self.s_mu, self.s_logvar)\n",
    "        self.s_prime = self.G_ST(self.t_tilde, self.zeta_tilde_s)\n",
    "        self.zs_mu, self.zs_logvar = self.E_T(torch.cat((self.real_S, self.t_tilde),1))\n",
    "        self.zeta_t_prime = reparameterize(self.zs_mu, self.zs_logvar)\n",
    "\n",
    "        \n",
    "        #T--->S forward pass had the same genorator...(3/1)\n",
    "        self.s_tilde = self.G_TS(self.real_T, self.prior_S) #shape checks out [BS, CH, H, W] ~ [5, 3, 224, 224] \n",
    "        self.t_mu, self.t_logvar= self.E_T(torch.cat((self.s_tilde,self.real_T),1))\n",
    "        self.zeta_tilde_t = reparameterize(self.t_mu, self.t_logvar)\n",
    "        self.t_prime = self.G_TS(self.s_tilde, self.zeta_tilde_t)\n",
    "        self.zt_mu, self.zt_logvar = self.E_S(torch.cat((self.real_T, self.s_tilde),1))\n",
    "        self.zeta_s_prime = reparameterize(self.zt_mu, self.zt_logvar)\n",
    "        \n",
    "    def backward_D(self, netD, real, fake):\n",
    "        pred_real = netD(real)\n",
    "        loss_D_real = self.ganloss(pred_real, True)\n",
    "        pred_fake = netD(fake.detach())\n",
    "        loss_D_fake = self.ganloss(pred_fake, False)\n",
    "\n",
    "        loss_D = (loss_D_real + loss_D_fake) * 0.5\n",
    "\n",
    "        return loss_D\n",
    "    \n",
    "    def backward_Discriminators(self): \n",
    "        self.loss_DS = self.backward_D(self.D_S, self.real_S, self.t_tilde.detach())\n",
    "        self.loss_DT = self.backward_D(self.D_T, self.real_T, self.s_tilde.detach())\n",
    "        \n",
    "        self.loss_DZs = self.backward_D(self.D_Zs, self.prior_S, self.zeta_tilde_s.detach())  #log(D_zs(zs) + log(1-(D_zs(E_s(S, G_ST(S, z_t))))))\n",
    "        self.loss_DZt = self.backward_D(self.D_Zt, self.prior_T, self.zeta_tilde_t.detach())  #log(D_zt(zt) + log(1-(D_zt(E_t(T, G_TS(T, z_s))))))\n",
    "\n",
    "        self.loss_D = self.loss_DS + self.loss_DT +self.loss_DZs +self.loss_DZt\n",
    "        \n",
    "        self.loss_D.backward()\n",
    "        \n",
    "        \n",
    "    def backward_Generators(self):\n",
    "        loss_G_S = self.ganloss(self.D_S(self.t_tilde), True)       #L(D_S(G_ST(S)))\n",
    "        loss_G_T = self.ganloss(self.D_T(self.s_tilde), True)       #L(D_T(G_TS(T)))   \n",
    "        \n",
    "        loss_G_S_z = self.ganloss(self.D_Zs(self.zeta_tilde_s), True)\n",
    "        loss_G_T_z = self.ganloss(self.D_Zt(self.zeta_tilde_t), True)\n",
    "        \n",
    "        #POTENTIALLY ADD IDENTITY LOSS? (done below) (removed)\n",
    "        self.idt_S = self.G_ST(self.real_T, self.prior_S)  #G_ST(t) ~ s  ~t           ***t_tilde\n",
    "        self. idt_T = self.G_TS(self.real_S, self.prior_T)  #G_TS(G_ST(s))          ***s_tilde\n",
    "        \n",
    "        loss_idt_S = self.identityloss(self.t_tilde, self.real_T) * 10 * 0.5\n",
    "        loss_idt_T = self.identityloss(self.s_tilde, self.real_S) * 10 * 0.5\n",
    "        \n",
    "        L_cyc_s = self.cycleloss(self.s_prime, self.real_S)  #|| G_TS(G_ST(S,zt), E_S(S,zeta_tilde_t))||1\n",
    "        L_cyc_t = self.cycleloss(self.t_prime, self.real_T)  #|| G_ST(G_TS(T,zs), E_T(T,zeta_tilde_s))||1\n",
    "        \n",
    "        #minimize NLL\n",
    "        L_cyc_zt = self.cycleloss(self.prior_T, self.zeta_t_prime) \n",
    "        L_cyc_zs = self.cycleloss(self.prior_S, self.zeta_s_prime) \n",
    "\n",
    "        \n",
    "        cycle_loss = L_cyc_s + L_cyc_t + loss_idt_S + loss_idt_T \n",
    "        self.loss_G = loss_G_S + loss_G_T +  cycle_loss +loss_G_S_z + loss_G_T_z \n",
    "        \n",
    "        \n",
    "#         kld_zt = kld_std_guss(self.t_mu, self.t_logvar).mean(0)\n",
    "#         kld_zs = kld_std_guss(self.s_mu, self.s_logvar).mean(0)\n",
    "        \n",
    "#         self.loss_G += (kld_zt + kld_zs) *0.025\n",
    "        self.loss_G.backward()\n",
    "        \n",
    "    def optimize(self):\n",
    "        self.forward_pass()\n",
    "####---------------------------------------####\n",
    "# Train Discriminators D_S, D_T, D_Zs, D_Zt   #\n",
    "####---------------------------------------####\n",
    "#         set_requires_grad([self.D_S, self.D_T, self.D_Zs, self.D_Zt], requires_grad=True)\n",
    "#         set_requires_grad([self.G_ST, self.G_TS, self.E_T, self.E_S], requires_grad=False)\n",
    "        self.optimizer_DS.zero_grad()\n",
    "        self.optimizer_DT.zero_grad()\n",
    "        \n",
    "        self.backward_Discriminators()\n",
    "        gnorm_D_A = torch.nn.utils.clip_grad_norm_(self.D_S.parameters(), 500)\n",
    "        gnorm_D_B = torch.nn.utils.clip_grad_norm_(self.D_T.parameters(), 500)\n",
    "        gnorm_D_zs = torch.nn.utils.clip_grad_norm_(self.D_Zs.parameters(),500)\n",
    "        gnorm_D_zt = torch.nn.utils.clip_grad_norm_(self.D_Zt.parameters(),500)\n",
    "\n",
    "        #separate optimizers for S and T?\n",
    "        self.optimizer_DS.step()\n",
    "        self.optimizer_DT.step()\n",
    "        \n",
    "        \n",
    "# ####------------------------------------------------####\n",
    "# # Train Generators and Encoders G_ST, G_TS, E_S, E_T   #\n",
    "# ####------------------------------------------------####\n",
    "#         set_requires_grad([self.D_S, self.D_T, self.D_Zs, self.D_Zt], requires_grad=False)\n",
    "#         set_requires_grad([self.G_ST, self.G_TS, self.E_T, self.E_S], requires_grad=True)\n",
    "        self.optimizer_GS.zero_grad()\n",
    "        self.optimizer_GT.zero_grad()\n",
    "        \n",
    "        self.backward_Generators()\n",
    "        \n",
    "        self.optimizer_GS.step()\n",
    "        self.optimizer_GT.step()\n",
    "        \n",
    "        return self.loss_G, self.loss_D, self.D_S, self.D_T, self.D_Zs, self.D_Zt, self.G_ST, self.G_TS, self.E_T, self.E_S\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialized\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4a9e27a2f2a4751948b270c916c6a98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 26.00 MiB (GPU 0; 10.58 GiB total capacity; 9.97 GiB already allocated; 13.12 MiB free; 10.30 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-7fc38b5233e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mG_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD_S\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD_T\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD_Zs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD_Zt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG_ST\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG_TS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mE_T\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mE_S\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mD_loss\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbest_d_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-41aaa9dfa4d1>\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;31m####---------------------------------------####\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;31m# Train Discriminators D_S, D_T, D_Zs, D_Zt   #\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-41aaa9dfa4d1>\u001b[0m in \u001b[0;36mforward_pass\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;31m#T--->S forward pass had the same genorator...(3/1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms_tilde\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG_TS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal_T\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprior_S\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#shape checks out [BS, CH, H, W] ~ [5, 3, 224, 224]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt_mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt_logvar\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE_T\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms_tilde\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal_T\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeta_tilde_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreparameterize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt_mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt_logvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/current_work/cycle_stuff/cycada/augmented_cyclegan/augmented_utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, noise)\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_parallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/current_work/cycle_stuff/cycada/augmented_cyclegan/augmented_modules.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input1, input2)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTwoInputModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m                 \u001b[0minput1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                 \u001b[0minput1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/current_work/cycle_stuff/cycada/augmented_cyclegan/augmented_modules.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, noise)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/current_work/cycle_stuff/cycada/augmented_cyclegan/augmented_modules.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input1, input2)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTwoInputModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m                 \u001b[0minput1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                 \u001b[0minput1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/current_work/cycle_stuff/cycada/augmented_cyclegan/augmented_modules.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input1, input2)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0moutput1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0moutput2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/current_work/cycle_stuff/cycada/augmented_cyclegan/augmented_modules.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, noise)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrsqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0mnorm_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_reshaped\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnorm_features\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mscale\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mshift\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 26.00 MiB (GPU 0; 10.58 GiB total capacity; 9.97 GiB already allocated; 13.12 MiB free; 10.30 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "history = {'epoch':[],'G_loss': [], 'D_loss':[], 'batch':[]}\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "model = Pixel_Level_Augmented_CycleGAN()\n",
    "best_g_loss = 1e6\n",
    "best_d_loss = 1e6\n",
    "\n",
    "n_epochs = 15\n",
    "\n",
    "for e in range(n_epochs):\n",
    "    for i, batch in tqdm(enumerate(train_dataloader)):\n",
    "        model.data_input(batch)\n",
    "        torch.cuda.empty_cache()\n",
    "        G_loss, D_loss, D_S, D_T, D_Zs, D_Zt, G_ST, G_TS, E_T, E_S = model.optimize()\n",
    "            \n",
    "        if D_loss < best_d_loss:\n",
    "            best_d_loss = D_loss\n",
    "            torch.save({'D_T': D_T.state_dict(), 'D_S': D_S.state_dict(), 'D_Zs': D_Zs.state_dict(), 'D_Zt': D_Zt.state_dict()}, '/hpc/home/srs108/current_work/cycle_stuff/saved_models/best_d.pt')\n",
    "            \n",
    "        if G_loss < best_g_loss:\n",
    "            best_g_loss = G_loss\n",
    "            torch.save({ 'G_ST': G_ST.state_dict(),'G_TS': G_TS.state_dict(), 'E_S':E_S.state_dict(), 'E_T':E_T.state_dict()}, '/hpc/home/srs108/current_work/cycle_stuff/saved_models/best_g.pt')\n",
    "            \n",
    "        \n",
    "        if (i+1) % 250 == 0:\n",
    "            with torch.no_grad():\n",
    "                now = datetime.datetime.now()\n",
    "                model.sample_images(val_dataloader, e, i, save=False)\n",
    "                print(f\"Iteration {i + 1}/{len(train_dataloader)} finished at {now.time()}\\n\\\n",
    "                [G Loss: {G_loss.item()}]\\t[D Loss: {D_loss.item()}]\")\n",
    "   \n",
    "            history['G_loss'].append(G_loss.item())\n",
    "            history['D_loss'].append(D_loss.item())\n",
    "            history['batch'].append(i+1)\n",
    "            history['epoch'].append(e+1)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
