{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure directory exists.\n",
      "On cuda:0\n"
     ]
    }
   ],
   "source": [
    "from augmented_modules import ResnetBlock, CondInstanceNorm, TwoInputSequential, CINResnetBlock, InstanceNorm2d\n",
    "from augmented_utils import *\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'On {device}')\n",
    "Tensor  = torch.cuda.FloatTensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for quicker debugging purposes\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, num_samples):\n",
    "        # Generate synthetic data (you can replace this with your actual data)\n",
    "        self.data1 = torch.randn(num_samples, 3, 224, 224)\n",
    "        self.data2 = torch.randn(num_samples, 3, 224, 224)\n",
    "        self.labels1 = torch.arange(num_samples)  # Dummy labels (you can modify this)\n",
    "        self.labels2 = torch.arange(num_samples)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data1)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = {\n",
    "              'D img': self.data1[idx],\n",
    "              'D pm' : self.labels1[idx],\n",
    "              'L img': self.data2[idx],\n",
    "              'L pm' : self.labels2[idx]\n",
    "        }\n",
    "        return sample\n",
    "\n",
    "# Create an instance of your custom dataset\n",
    "num_samples = 3000  # Adjust as needed\n",
    "custom_dataset = CustomDataset(num_samples)\n",
    "\n",
    "# Create a DataLoader\n",
    "batch_size = 5\n",
    "train_dataloader = DataLoader(custom_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# norm_layer_ = functools.partial(nn.InstanceNorm2d, affine=False)\n",
    "# mod = Latent_Encoder(nlatent=3, input_nc=3, nef=32, norm_layer=norm_layer_)\n",
    "# ex = torch.rand((5,3,224,224))\n",
    "\n",
    "# g = mod(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Latent_Encoder(nn.Module):\n",
    "    def __init__(self, nlatent, input_nc, nef, norm_layer):\n",
    "        super(Latent_Encoder, self).__init__()\n",
    "        \n",
    "        use_bias = False\n",
    "\n",
    "        kw = 3\n",
    "        sequence = [\n",
    "            nn.Conv2d(input_nc, nef, kernel_size=kw, stride=2, padding=1, bias=True),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.Conv2d(nef, 2*nef, kernel_size=kw, stride=2, padding=1, bias=use_bias),\n",
    "            norm_layer(2*nef),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.Conv2d(2*nef, 4*nef, kernel_size=kw, stride=2, padding=1, bias=use_bias),\n",
    "            norm_layer(4*nef),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.Conv2d(4*nef, 8*nef, kernel_size=kw, stride=2, padding=1, bias=use_bias),\n",
    "            norm_layer(8*nef),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.Conv2d(8*nef, 8*nef, kernel_size=4, stride=1, padding=0, bias=use_bias),\n",
    "            norm_layer(8*nef),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "        ]\n",
    "\n",
    "        self.conv_modules = nn.Sequential(*sequence)\n",
    "\n",
    "        # make sure we return mu and logvar for latent code normal distribution\n",
    "        self.enc_mu = nn.Conv2d(8*nef, nlatent, kernel_size=11, stride=1, padding=0, bias=True)\n",
    "        self.enc_logvar = nn.Conv2d(8*nef, nlatent, kernel_size=11, stride=1, padding=0, bias=True)\n",
    "\n",
    "    def forward(self, input):\n",
    "\n",
    "        conv_out = self.conv_modules(input)\n",
    "        mu = self.enc_mu(conv_out)\n",
    "        logvar = self.enc_logvar(conv_out)\n",
    "        \n",
    "        return mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reparameterize(mu, logvar):\n",
    "    std = torch.exp(0.5 * logvar)\n",
    "    eps = torch.randn_like(std)\n",
    "    return mu + eps * std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pixel_Level_Augmented_CycleGAN():\n",
    "    def __init__(self):\n",
    "        super(Pixel_Level_Augmented_CycleGAN,self).__init__()\n",
    "        \n",
    "        norm_layer_C = CondInstanceNorm\n",
    "        norm_layer_ = functools.partial(nn.InstanceNorm2d, affine=False)\n",
    "        \n",
    "        self.G_ST = CINResnetGenerator(nlatent=16, input_nc=3, output_nc=3, ngf=64, norm_layer=norm_layer_C,\n",
    "                 use_dropout=False, n_blocks=3, gpu_ids=[], padding_type='reflect')\n",
    "        \n",
    "        self.G_TS = CINResnetGenerator(nlatent=16, input_nc=3, output_nc=3, ngf=64, norm_layer=norm_layer_C,\n",
    "                 use_dropout=False, n_blocks=3, gpu_ids=[], padding_type='reflect')\n",
    "\n",
    "        self.D_T = NLayerDiscriminator(input_nc=3, ndf=64, n_layers=4, norm_layer=norm_layer_)\n",
    "        self.D_S = NLayerDiscriminator(input_nc=3, ndf=64, n_layers=4, norm_layer=norm_layer_)\n",
    "\n",
    "        self.D_z = Discriminator_Latent(nlatent=16, ndf=64)\n",
    "        \n",
    "        self.E_S = Latent_Encoder(nlatent=16, input_nc=6, nef=32, norm_layer=norm_layer_)\n",
    "        self.E_T = Latent_Encoder(nlatent=16, input_nc=6, nef=32, norm_layer=norm_layer_)\n",
    "\n",
    "        self.G_ST.to(device)\n",
    "        self.G_TS.to(device)\n",
    "        self.E_S.to(device)\n",
    "        self.E_T.to(device)\n",
    "        self.D_S.to(device)\n",
    "        self.D_T.to(device)\n",
    "        self.D_z.to(device)\n",
    "\n",
    "\n",
    "        self.ganloss = GANLoss().to(device)       \n",
    "        self.cycleloss = torch.nn.L1Loss().to(device)               #difference between reconstructed img and original\n",
    "        self.mseloss = torch.nn.MSELoss().to(device)       #difference between domain classifications between input img and generator output\n",
    "        self.identityloss = torch.nn.L1Loss().to(device)\n",
    "        \n",
    "        self.optimizer_GS = torch.optim.Adam(itertools.chain(self.G_ST.parameters(), self.E_S.parameters()), \n",
    "                                            lr=2e-5, betas=(0.5,0.999))\n",
    "        \n",
    "        self.optimizer_GT = torch.optim.Adam(itertools.chain(self.G_TS.parameters(), self.E_T.parameters()), \n",
    "                                            lr=2e-5, betas=(0.5,0.999))\n",
    "        \n",
    "        self.optimizer_DS = torch.optim.Adam(self.D_S.parameters()\n",
    "                                             , lr = 1e-5, betas = (0.5,0.9))\n",
    "        self.optimizer_DT = torch.optim.Adam(self.D_T.parameters(), \n",
    "                                             lr = 1e-5, betas = (0.5,0.9))\n",
    "\n",
    "\n",
    "        self.G_ST.apply(weights_init_normal)\n",
    "        self.G_TS.apply(weights_init_normal)\n",
    "        self.D_S.apply(weights_init_normal)\n",
    "        self.D_T.apply(weights_init_normal)\n",
    "        self.D_z.apply(weights_init_normal)\n",
    "\n",
    "        print('initialized')\n",
    "        \n",
    "    def data_input(self, batch):\n",
    "        self.real_S = batch['D img'].type(Tensor)\n",
    "        self.real_T = batch['L img'].type(Tensor)\n",
    "        self.real_lbl = batch['D pm'].type(Tensor).float()\n",
    "        self.prior = self.real_S.data.new(self.real_S.size(0), 16, 1, 1).normal_(0, 1)\n",
    "\n",
    "                  \n",
    "    def forward_pass(self):\n",
    "        self.t_tilde = self.G_ST(self.real_S, self.prior) #shape checks out [BS, CH, H, W] ~ [5, 3, 224, 224] \n",
    "        self.s_tilde = self.G_TS(self.real_T, self.prior) #shape checks out [BS, CH, H, W] ~ [5, 3, 224, 224] \n",
    "        \n",
    "        \n",
    "        self.s_mu, self.s_logvar = self.E_S(torch.cat((self.t_tilde, self.real_S), 1))\n",
    "        \n",
    "        self.t_mu, self.t_logvar= self.E_T(torch.cat((self.s_tilde,self.real_T),1))\n",
    "\n",
    "        self.zeta_tilde_s = reparameterize(self.s_mu, self.s_logvar)\n",
    "        self.zeta_tilde_t = reparameterize(self.t_mu, self.t_logvar)\n",
    "        \n",
    "        self.s_recon = self.G_TS(self.t_tilde, self.zeta_tilde_s)\n",
    "        self.t_recon = self.G_TS(self.s_tilde, self.zeta_tilde_t)\n",
    "        \n",
    "        print(self.real_S.shape, self.t_tilde.shape)\n",
    "        self.zeta_t_prime = self.E_T(torch.cat((self.real_S, self.t_tilde),1))\n",
    "        self.zeta_s_primt = self.E_S(torch.cat((self.real_T, self.s_tilde),1))\n",
    "        \n",
    "        \n",
    "    def backward_D(self, netD, real, fake):\n",
    "         \n",
    "        # Real\n",
    "        pred_real = netD(real)\n",
    "        if self.gan_mode == 'wgangp':\n",
    "            loss_D_real = -torch.mean(pred_real)\n",
    "        else: loss_D_real = self.ganloss(pred_real, True)\n",
    "        \n",
    "        # Fake\n",
    "        pred_fake = netD(fake.detach())\n",
    "        if self.gan_mode == 'wgangp':\n",
    "            loss_D_fake = torch.mean(pred_fake)\n",
    "        else: loss_D_fake = self.ganloss(pred_fake, False)\n",
    "        \n",
    "        # Combined loss and calculate gradients\n",
    "\n",
    "        if self.gan_mode == \"wgangp\":\n",
    "            gradient_penalty, gradients = cal_gradient_penalty(netD,real,fake,device)\n",
    "            gradient_penalty.backward(retain_graph=True)\n",
    "        \n",
    "            loss_D = loss_D_real + loss_D_fake + 10 * gradient_penalty\n",
    "\n",
    "        else:\n",
    "            loss_D = (loss_D_real + loss_D_fake) * 0.5\n",
    "\n",
    "        return loss_D\n",
    "\n",
    "    def optimize(self):\n",
    "        self.forward_pass()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialized\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "400ca4a20b964a28a4f9928454e4e494",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 224, 224]) torch.Size([5, 3, 224, 224])\n",
      "torch.Size([5, 3, 224, 224]) torch.Size([5, 3, 224, 224])\n",
      "torch.Size([5, 3, 224, 224]) torch.Size([5, 3, 224, 224])\n",
      "torch.Size([5, 3, 224, 224]) torch.Size([5, 3, 224, 224])\n",
      "torch.Size([5, 3, 224, 224]) torch.Size([5, 3, 224, 224])\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-14a647145064>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-6473190483aa>\u001b[0m in \u001b[0;36mdata_input\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdata_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal_S\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'D img'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal_T\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'L img'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal_lbl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'D pm'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = {'epoch':[],'G_loss': [], 'DS_loss':[], 'DT_loss':[], 'batch':[]}\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "model = Pixel_Level_Augmented_CycleGAN()\n",
    "best_gen_loss = 1e6\n",
    "best_DT_loss = 1e6\n",
    "best_DS_loss = 1e6\n",
    "\n",
    "n_epochs = 15\n",
    "\n",
    "for e in range(n_epochs):\n",
    "    for i, batch in tqdm(enumerate(train_dataloader)):\n",
    "        model.data_input(batch)\n",
    "        model.optimize()\n",
    "        \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
