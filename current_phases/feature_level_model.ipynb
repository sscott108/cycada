{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure directory exists.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76dded98521e4103b6721e9d38faeef2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=31475.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "475c2170cc0a45c4be1dfa3743e5d8a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from cycada_utils import *\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "tr = CyDataset()\n",
    "train, val = train_test_split(tr, test_size=0.2, random_state=42)\n",
    "train_dataloader = DataLoader(\n",
    "    train,\n",
    "    batch_size=5,\n",
    "    shuffle=True)\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    val,\n",
    "    batch_size=1,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5081],\n",
       "        [0.5117],\n",
       "        [0.5054],\n",
       "        [0.5125],\n",
       "        [0.5147]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cant use softmax when i have a single output.\n",
    "class FeatureDiscriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FeatureDiscriminator, self).__init__()\n",
    "        self.discriminator = nn.Sequential(\n",
    "            nn.Linear(1, 500),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(500, 500),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(500, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, score):\n",
    "        out = self.discriminator(score)\n",
    "        return out\n",
    "mod = FeatureDiscriminator()\n",
    "x = mod(ft)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = NLayerDiscriminator(3, 64, 4, nn.InstanceNorm2d)\n",
    "img = torch.rand((5, 3,224,224))\n",
    "ft=torch.rand((5,1))\n",
    "yy = mod(img)\n",
    "target_label = torch.zeros(x.size()[0]).long()\n",
    "# x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_discriminator_output(output_tensor):\n",
    "    # Ensure binary_tensor is on the same device as output_tensor\n",
    "    binary_tensor = torch.where(output_tensor > 0, torch.tensor(1).to(output_tensor.device), torch.tensor(0).to(output_tensor.device))\n",
    "    \n",
    "    # Count the number of 1s in each subarray\n",
    "    count_ones = torch.sum(binary_tensor, dim=(2, 3))\n",
    "#     print(count_ones)\n",
    "    # Ensure majority_tensor is on the same device as output_tensor\n",
    "    majority_tensor = torch.where(count_ones > 72, torch.tensor(1).to(output_tensor.device), torch.tensor(0).to(output_tensor.device))\n",
    "    \n",
    "    return majority_tensor.view(-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[80],\n",
      "        [84],\n",
      "        [81],\n",
      "        [82],\n",
      "        [72]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([5])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yy = process_discriminator_output(yy)\n",
    "yy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(out, target=None, feature=False):\n",
    "    device = out.device  # Get the device of the input tensor\n",
    "    \n",
    "#     if target is None:\n",
    "#         _, label = torch.max(out.data, 1)\n",
    "#         return label.to(device)\n",
    "#     else:\n",
    "    if feature:\n",
    "        threshold = torch.tensor([0.5], device=device)\n",
    "        label = torch.where(out.data > threshold, \n",
    "                            torch.tensor(1).to(device), \n",
    "                            torch.tensor(0).to(device)).squeeze(1)\n",
    "    else: label = out\n",
    "\n",
    "    acc = (label == target).sum().item() / target.size()[0]\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 1, 1, 0])\n",
      "tensor([1, 1, 1, 1, 0])\n",
      "tensor([0, 0, 0, 0, 0])\n",
      "0.2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction(yy, target_label,feature=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5016],\n",
       "        [0.4994],\n",
       "        [0.5023],\n",
       "        [0.4985],\n",
       "        [0.4953]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction(x, target=target_label, feature=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feature_Level_Adaptation():\n",
    "    def __init__(self, gan_mode='wgangp'):\n",
    "        super(Feature_Level_Adaptation,self).__init__()\n",
    "        self.gan_mode = gan_mode\n",
    "        \n",
    "        generator_checkpoint = torch.load('/datacommons/carlsonlab/srs108/cicada/pixel_level/best_gens.pt')\n",
    "        discriminator_checkpoint1 = torch.load('/datacommons/carlsonlab/srs108/cicada/pixel_level/best_DS.pt')\n",
    "        discriminator_checkpoint2 = torch.load('/datacommons/carlsonlab/srs108/cicada/pixel_level/best_DT.pt')\n",
    "\n",
    "        #PHASE ONE~source task model        \n",
    "        self.f_s = Multi_City_CNN()\n",
    "        self.f_s.load_state_dict(torch.load('dlm4.pt'))\n",
    "        \n",
    "        #PHASE TWO~pixel level adaptation\n",
    "        norm_layer_G = functools.partial(nn.BatchNorm2d, affine=True, track_running_stats=True)\n",
    "        norm_layer_D = functools.partial(nn.InstanceNorm2d, affine=False)\n",
    "        self.G_ST = ResnetGenerator(3, 3, 64, norm_layer=norm_layer_G, use_dropout=False, n_blocks=2)\n",
    "        self.G_ST.load_state_dict(generator_checkpoint['G_ST'])\n",
    "        \n",
    "        self.G_TS = ResnetGenerator(3, 3, 64, norm_layer=norm_layer_G, use_dropout=False, n_blocks=2)\n",
    "        self.G_TS.load_state_dict(generator_checkpoint['G_TS'])\n",
    "        \n",
    "        self.D_T = NLayerDiscriminator(input_nc=3, ndf=64, n_layers=4, norm_layer=norm_layer_D)\n",
    "        self.D_T.load_state_dict(discriminator_checkpoint2['D_T'])\n",
    "        self.D_S = NLayerDiscriminator(input_nc=3, ndf=64, n_layers=4, norm_layer=norm_layer_D)\n",
    "        self.D_S.load_state_dict(discriminator_checkpoint1['D_S'])\n",
    "        \n",
    "        #PHASE THREE~feature space adaptation\n",
    "        self.D_ft = FeatureDiscriminator()\n",
    "        self.f_t = LeNet(3)\n",
    "\n",
    "        self.G_ST.to(device)\n",
    "        self.G_TS.to(device)\n",
    "        self.D_S.to(device)\n",
    "        self.D_T.to(device)\n",
    "        self.f_s.to(device)\n",
    "        self.D_ft.to(device)\n",
    "        self.f_t.to(device)\n",
    "\n",
    "\n",
    "        self.ganloss = GANLoss(gan_mode=self.gan_mode).to(device)       #use to fool discriminator\n",
    "        self.cycleloss = torch.nn.L1Loss().to(device)               #difference between reconstructed img and original\n",
    "        self.mseloss = torch.nn.MSELoss().to(device)       #difference between domain classifications between input img and generator output\n",
    "        self.identityloss = torch.nn.L1Loss().to(device)\n",
    "        self.ftloss = torch.nn.modules.CrossEntropyLoss().to(device)            #difference between generator output from input img and input img\n",
    "\n",
    "        \n",
    "        self.optimizer_G = torch.optim.Adam(itertools.chain(self.G_ST.parameters(), self.G_TS.parameters()), lr=2e-5, betas=(0.5,0.999))\n",
    "        self.optimizer_DS = torch.optim.Adam(self.D_S.parameters(), lr = 1e-5, betas = (0.5,0.9))\n",
    "        self.optimizer_DT = torch.optim.Adam(self.D_T.parameters(), lr = 1e-5, betas = (0.5,0.9))\n",
    "        \n",
    "        self.optimizer_f_s = torch.optim.Adam(self.f_s.parameters(), lr=1e-4, betas=(0.5, 0.999))    \n",
    "        self.optimizer_f_t = torch.optim.Adam(self.f_t.parameters(), lr=1e-5, betas=(0.5, 0.999))    #different learning rate??\n",
    "        self.optimizer_D_ft = torch.optim.Adam(self.D_ft.parameters(), lr = 1e-5, betas = (0.5,0.9))\n",
    "\n",
    "        \n",
    "        self.D_ft.apply(weights_init_normal)\n",
    "        self.f_t.apply(weights_init_normal)\n",
    "\n",
    "        \n",
    "    def data_input(self, batch):\n",
    "        self.real_S = batch['D img'].type(Tensor)\n",
    "        self.real_T = batch['L img'].type(Tensor)\n",
    "        self.real_lbl = batch['D pm'].type(Tensor).float()\n",
    "\n",
    "        self.source_label = torch.ones(self.real_S.size()[0]).long().to(device)\n",
    "        self.target_label = torch.zeros(self.real_T.size()[0]).long().to(device)\n",
    "        \n",
    "    def sample_images(self, dataloader, epochs, iters, save = False):\n",
    "        source = next(iter(dataloader))\n",
    "        self.G_ST.eval()\n",
    "        self.G_TS.eval()\n",
    "        real_source = source['D img'].type(Tensor) \n",
    "        fake_target = self.G_ST(real_source).detach()\n",
    "        real_target = source['L img'].type(Tensor)\n",
    "        real_lbl= source['D pm'].type(Tensor).float()\n",
    "        fake_source = self.G_TS(real_target).detach()\n",
    "\n",
    "        recons = self.G_TS(fake_target).detach()\n",
    "        recont = self.G_ST(fake_source).detach() \n",
    "\n",
    "        real_S = make_grid(real_source, nrow=5, normalize=True, scale_each=True, padding=1)\n",
    "        fake_T = make_grid(fake_target, nrow=5, normalize=True, scale_each=True, padding=1)\n",
    "        reconS = make_grid(recons, nrow=5, normalize=True, scale_each=True, padding=1)\n",
    "        real_T = make_grid(real_target, nrow=5, normalize=True, scale_each=True, padding=1)\n",
    "        fake_S = make_grid(fake_source, nrow=5, normalize=True, scale_each=True, padding=1)\n",
    "        reconT = make_grid(recont, nrow=5, normalize=True, scale_each=True, padding=1)\n",
    "        # Arange images along y-axis    \n",
    "        image_grid = torch.cat((real_S, fake_T, reconS, real_T, fake_S, reconT), 2)\n",
    "        plt.imshow(image_grid.cpu().permute(1,2,0))\n",
    "        plt.title('Real Source vs Fake Target vs Recon Source | Real Target vs Fake Source vs Recon Target')\n",
    "        plt.axis('off')\n",
    "        plt.gcf().set_size_inches(10, 6)\n",
    "        if save:\n",
    "            plt.savefig(os.path.join('Figure_PDFs', f'epoch_{str(e+1)}_iter{str(i+1)}.png'), bbox_inches='tight', pad_inches=0, facecolor='white')\n",
    "        plt.show();\n",
    "        \n",
    "    def forward_pass(self):\n",
    "        self.fake_t = self.G_ST(self.real_S)\n",
    "        self.fake_s = self.G_TS(self.real_T)             \n",
    "        \n",
    "        self.recov_s = self.G_TS(self.fake_t)\n",
    "        self.recov_t = self.G_ST(self.fake_s)\n",
    "        \n",
    "        #compute MSE from PM values ***predicted*** from real image and fake image (same pm vals tho!!)\n",
    "        #DO NOT ASSESS WITH REAL PM LABEL, BUT WITH PREDICTION\n",
    "        \n",
    "        self.pm_from_real_S  = self.f_s(self.real_S).squeeze(1)\n",
    "        self.pm_from_fake_T  = self.f_s(self.fake_t.detach()).squeeze(1)\n",
    "        \n",
    "        self.pm_from_real_T  = self.f_s(self.real_T).squeeze(1)\n",
    "        self.pm_from_fake_S  = self.f_s(self.fake_s.detach()).squeeze(1)\n",
    "        \n",
    "        self.pred_source  = self.D_ft(self.f_t(self.fake_t.detach()))\n",
    "        self.pred_target  = self.D_ft(self.f_t(self.real_T))\n",
    "\n",
    "        self.dft_acc_1 = prediction(self.pred_source,self.source_label, feature = True)\n",
    "        self.dft_acc_2 = prediction(self.pred_target, self.target_label, feature = True)\n",
    "\n",
    "        self.score_acc_D_ft = (self.dft_acc_1 + self.dft_acc_2)/2\n",
    "        print(self.score_acc_D_ft)\n",
    "    def source_task(self):\n",
    "        #L_task(f_s, G_ST(S), p(fS,S))\n",
    "        self.sem_source  = self.mseloss(self.pm_from_real_S, self.pm_from_fake_T)  #MSE(f_s(S), f_s(G_ST(S)))                  \n",
    "\n",
    "        #L_task(f_s, G_TS(T), p(fS,T))\n",
    "        self.sem_targ    = self.mseloss(self.pm_from_real_T, self.pm_from_fake_S)  #MSE(f_s(T), f_s(G_TS(T))) \n",
    "        self.sem_loss  = (self.sem_source + self.sem_targ)/2\n",
    "        \n",
    "        self.optimizer_f_s.step\n",
    "        \n",
    "    def backward_D(self, netD, real, noise):\n",
    "         \n",
    "        # Real\n",
    "        pred_real = netD(real)\n",
    "        if self.gan_mode == 'wgangp':\n",
    "            loss_D_real = -torch.mean(pred_real)\n",
    "        else: loss_D_real = self.ganloss(pred_real, True)\n",
    "        \n",
    "        # Fake\n",
    "        pred_fake = netD(noise.detach())\n",
    "        if self.gan_mode == 'wgangp':\n",
    "            loss_D_fake = torch.mean(pred_fake)\n",
    "        else: loss_D_fake = self.ganloss(pred_fake, False)\n",
    "        \n",
    "        # Combined loss and calculate gradients\n",
    "\n",
    "        if self.gan_mode == \"wgangp\":\n",
    "            gradient_penalty, gradients = cal_gradient_penalty(netD,real,noise,device)\n",
    "            gradient_penalty.backward(retain_graph=True)\n",
    "        \n",
    "            loss_D = loss_D_real + loss_D_fake + 10 * ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "\n",
    "        else:\n",
    "            loss_D = (loss_D_real + loss_D_fake) * 0.5\n",
    "\n",
    "        true_labels = torch.ones(real.size()[0]).long()\n",
    "        fake_labels = torch.zeros(noise.detach().size()[0]).long()\n",
    "        pred_real   = process_discriminator_output(pred_real)\n",
    "        pred_fake   = process_discriminator_output(pred_fake)\n",
    "        true_acc = prediction(pred_real.cpu(), true_labels,feature=False)\n",
    "        fake_acc = prediction(pred_fake.cpu(), fake_labels,feature=False)\n",
    "        acc = (true_acc + fake_acc) * 0.5\n",
    "        return loss_D , acc\n",
    "\n",
    "        \n",
    "    def backward_DS(self):\n",
    "        self.DS_Loss_wgan, _ = self.backward_D(self.D_S, self.real_S ,self.fake_s.detach())\n",
    "#         self.DS_Loss_wgan.backward()\n",
    "        self.optimizer_DS.step()\n",
    "        \n",
    "    def backward_DT(self):\n",
    "        self.DT_Loss_wgan, _ = self.backward_D(self.D_T, self.real_T, self.fake_t.detach())\n",
    "#         self.DT_Loss_wgan.backward()\n",
    "        self.optimizer_DT.step()\n",
    "        \n",
    "    def backward_D_feat(self):\n",
    "        \n",
    "        self.pred_source  = self.D_ft(self.f_t(self.fake_t.detach())).squeeze(1)\n",
    "        self.pred_target  = self.D_ft(self.f_t(self.real_T)).squeeze(1)\n",
    "        \n",
    "        loss_D_ft_s = self.ganloss(self.pred_source, Fake)\n",
    "#         loss_D_ft_s = self.ftloss(self.pred_source.type(Tensor), self.source_label.type(Tensor))\n",
    "       \n",
    "        # Target\n",
    "        loss_D_ft_t = self.ganloss(self.pred_target, True)\n",
    "#         loss_D_ft_t = self.ftloss(self.pred_target.type(Tensor), self.target_label.type(Tensor))\n",
    "        # Combined loss\n",
    "        \n",
    "        self.loss_D_ft_adv = (loss_D_ft_s + loss_D_ft_t) * 0.5\n",
    "        self.loss_D_ft_adv.backward()\n",
    "        self.optimizer_D_ft.step()\n",
    "\n",
    "        \n",
    "    def backward_G(self):\n",
    "        #GAN loss (identity loss in cycleGAN/pixel level for cycada)\n",
    "        \n",
    "        self.idt_S = self.G_ST(self.real_T)  #G_ST(G_TS(t)) ~ s\n",
    "        self. idt_T = self.G_TS(self.real_S)  #G_TS(G_ST(s))\n",
    "        self.loss_idt_S = self.identityloss(self.idt_S, self.real_T) * 10\n",
    "        self.loss_idt_T = self.identityloss(self.idt_T, self.real_S) * 10\n",
    "        \n",
    "        if self.gan_mode == 'wgangp':\n",
    "            self.DS_GST_S = self.D_S(self.fake_t)\n",
    "            self.loss_G_S = -torch.mean(self.DS_GST_S)\n",
    "\n",
    "            self.DT_GTS_T = self.D_T(self.fake_s)\n",
    "            self.loss_G_T = -torch.mean(self.DT_GTS_T)\n",
    "            \n",
    "        else:\n",
    "            self.loss_G_S = self.ganloss(self.D_S(self.fake_t), True)       #L(D_S(G_ST(S)))\n",
    "            self.loss_G_T = self.ganloss(self.D_T(self.fake_s), True)       #L(D_T(G_TS(T)))    \n",
    "        \n",
    "        # cycle loss  (L1 Loss)      \n",
    "        self.loss_cycle_S   = self.cycleloss(self.recov_s, self.real_S) * 10   # Lcyc(G_TS(G_ST(S)), S) * λ \n",
    "        self.loss_cycle_T   = self.cycleloss(self.recov_t, self.real_T) * 10  # Lcyc(G_ST(G_TS(T)), T) * λ \n",
    "        \n",
    "        self.loss_G = self.loss_G_S + self.loss_G_T + self.loss_cycle_S + self.loss_cycle_T + self.loss_idt_S + self.loss_idt_T\n",
    "\n",
    "        self.sem_loss_source    = self.mseloss(self.pm_from_real_S, self.pm_from_fake_T)  #Ltask(fs, G_TS(T), p(fs, T))                   \n",
    "        self.sem_loss_targ      = self.mseloss(self.pm_from_real_T,self.pm_from_fake_S)   #Ltask(fs, G_ST(S), p(fs, S))\n",
    "        \n",
    "        self.loss_G += self.sem_loss_source + self.sem_loss_targ\n",
    "#         self.loss_G.backward()\n",
    "        self.optimizer_G.step()\n",
    "    \n",
    "    def backward_ft(self):\n",
    "        main_task_pred = self.f_t(self.fake_t.detach()).squeeze(1)\n",
    "        main_task_loss = self.mseloss(main_task_pred, self.real_lbl)\n",
    "        \n",
    "        if self.score_acc_D_ft > 0.6:\n",
    "            pred_target_main = self.D_ft(self.f_t(self._T))  #Dft(ft(T)) \n",
    "            \n",
    "        main_task_loss.backward()\n",
    "        self.optimizer_f_t.step()\n",
    "        \n",
    "    def optimize(self):\n",
    "        self.forward_pass()\n",
    "        \n",
    "#         fs (pretrained already, no backprop)\n",
    "        set_requires_grad([self.f_s],requires_grad=False)\n",
    "        self.optimizer_f_s.zero_grad()\n",
    "        self.source_task()\n",
    "        \n",
    "# -------------------------------------------------------------------------------------------------------\n",
    "# Generators G_ST and G_TS ;\n",
    "# -------------------------------------------------------------------------------------------------------\n",
    "        set_requires_grad([self.D_S, self.D_T],requires_grad=False)\n",
    "        set_requires_grad([self.G_ST, self.G_TS],requires_grad=False)\n",
    "        self.optimizer_G.zero_grad()\n",
    "        self.optimizer_f_s.zero_grad()\n",
    "        self.backward_G()\n",
    "        \n",
    "# -------------------------------------------------------------------------------------------------------\n",
    "#  Discriminators S and Critic T;\n",
    "# -------------------------------------------------------------------------------------------------------\n",
    "  \n",
    "#         for i in range(5):\n",
    "        self.optimizer_DS.zero_grad()\n",
    "        self.backward_DS()\n",
    "        \n",
    "#         for _ in range(5):\n",
    "        self.optimizer_DT.zero_grad()\n",
    "        self.backward_DT()\n",
    "        \n",
    "        \n",
    "# -------------------------------------------------------------------------------------------------------\n",
    "#  Phase 3; Feature Discriminator and task model\n",
    "# -------------------------------------------------------------------------------------------------------\n",
    "\n",
    "        set_requires_grad([self.f_t], True)\n",
    "        set_requires_grad([self.D_ft], False)\n",
    "        \n",
    "        self.optimizer_f_t.zero_grad()\n",
    "        self.backward_ft()\n",
    "        \n",
    "        \n",
    "        set_requires_grad([self.f_t], False)\n",
    "        set_requires_grad([self.D_ft], True)\n",
    "        self.optimizer_D_ft.zero_grad()\n",
    "        self.backward_D_feat()\n",
    "        return self.loss_G, self.DS_Loss_wgan, self.DT_Loss_wgan, self.D_S, self.D_T, self.G_ST, self.G_TS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c6ae6f4178045debc6c3a4bb5b35d7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.7\n",
      "0.8\n",
      "0.6\n",
      "0.7\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.2\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.4\n",
      "0.4\n",
      "0.5\n",
      "0.5\n",
      "0.4\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.4\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.4\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.4\n",
      "0.3\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.4\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-111-15150f7b52fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mG_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDS_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDT_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGST\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGTS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;31m#         model.sample_images(val_dataloader, e, i, save=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#         if DS_loss < best_DS_loss:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-110-c2c4a1bfb4b6>\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0mset_requires_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mD_ft\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_D_ft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward_D_feat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_G\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDS_Loss_wgan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDT_Loss_wgan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mD_S\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mD_T\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG_ST\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG_TS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-110-c2c4a1bfb4b6>\u001b[0m in \u001b[0;36mbackward_D_feat\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward_D_feat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred_source\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mD_ft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_t\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfake_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred_target\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mD_ft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_t\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal_T\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-99-8e18275bf163>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, score)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFeatureDiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   1455\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1456\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1457\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1458\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = {'epoch':[],'G_loss': [], 'DS_loss':[], 'DT_loss':[], 'batch':[]}\n",
    "torch.cuda.empty_cache()\n",
    "model = Feature_Level_Adaptation(gan_mode='wgangp')\n",
    "best_gen_loss = 1e6\n",
    "best_DT_loss = 1e6\n",
    "best_DS_loss = 1e6\n",
    "\n",
    "n_epochs = 200\n",
    "\n",
    "for e in range(n_epochs):\n",
    "    for i, batch in tqdm(enumerate(train_dataloader)):\n",
    "        model.data_input(batch)\n",
    "        G_loss, DS_loss, DT_loss, DS, DT, GST, GTS = model.optimize()\n",
    "#         model.sample_images(val_dataloader, e, i, save=True)\n",
    "#         if DS_loss < best_DS_loss:\n",
    "#             best_DS_loss = DS_loss\n",
    "#             torch.save({ 'D_S': DS.state_dict()}, 'best_DS.pt')\n",
    " \n",
    "#         if DT_loss < best_DT_loss:\n",
    "#             best_DT_loss = DT_loss\n",
    "#             torch.save({'D_T': DT.state_dict()}, 'best_DT.pt')\n",
    "            \n",
    "#         if G_loss < best_gen_loss:\n",
    "#             best_gen_loss = G_loss\n",
    "#             torch.save({ 'G_ST': GST.state_dict(),'G_TS': GTS.state_dict()}, 'best_gens.pt')\n",
    "            \n",
    "        \n",
    "#         if (i+1) % 250 == 0:\n",
    "#             with torch.no_grad():\n",
    "#                 model.sample_images(val_dataloader, e, i, save=True)\n",
    "                \n",
    "#                 history['G_loss'].append(G_loss.item())\n",
    "#                 history['DS_loss'].append(DS_loss.item())\n",
    "#                 history['DT_loss'].append(DT_loss.item())\n",
    "#                 history['batch'].append(i+1)\n",
    "#                 history['epoch'].append(e+1)\n",
    "#     now = datetime.datetime.now()\n",
    "#     print(f\"Epoch {e + 1}/{n_epochs} finished at {now.time()}\\n\\\n",
    "#     [G Loss: {G_loss.item()}]\\t[D Loss: {DS_loss.item()+ DT_loss.item()}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
